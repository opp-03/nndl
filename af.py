# -*- coding: utf-8 -*-
"""AF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QiGlR9w06-N-2ZvIaTRtVTgOCai7Px9c
"""

import numpy as np
import matplotlib.pyplot as plt
import numpy as np

def binaryStep(x):
  ''' It returns '0' is the input is less than zero otherwise it returns one '''
  return np.heaviside(x,1)

def linear(x):
  ''' y= f(x) It returns the input as it is'''
  return x

x=np.linspace(-10,10)
plt.plot(x,binaryStep(x))
plt.axis('tight')
plt.title('Activation Function: binaryStep')
plt.show()

x=np.linspace(-10,10)
plt.plot(x, linear(x))
#plt.axis('tight')
plt.title('Activation Function : Linear')
plt.show()

def sigmoid(x):
  '''It returns 1/(1+exp(-x)). where the values lies between zero and one'''
  return 1/(1+np.exp(-x))

x=np.linspace(-10,10)
plt.plot(x, sigmoid(x))
plt.axis('tight')
plt.title('Activation Function : Sigmoid')
plt.show()

def tanh(x):
  ''' it returns the value (1-exp(-2x))/(1+exp(-2x)) and the value returned will b'''
  return np.tanh(x)

x=np.linspace(-10,10)
plt.plot(x, tanh(x))
#plt.axis('tight')
plt.title('Activation Function : Tanh')
plt.show()

def  RELU(x):
  ''' It returns zero if the input is less than zero otherwise it returns the give'''
  x1=[]
  for i in x:
    if i<0:
      x1.append(0)
    else:
      x1.append(i)
    return x1

x=np.linspace(-10,10)
plt.plot(x,y)
plt.axis('tight')
plt.title('Activation Function : RELU')
plt.show()

def softmax(x):
    """Compute softmax values for each sets of scores in x."""
    return np.exp(x) / np.sum(np.exp(x), axis=0)

x=np.linspace(-10,10)
plt.plot(x, softmax(x))
#plt.axis('tight')
plt.title('Activation Function : Softmax')
plt.show()